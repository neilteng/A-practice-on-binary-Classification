{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw1",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "lPcOmb6ZILqm",
        "colab_type": "code",
        "outputId": "a19cfbd0-4cfb-4662-ae9b-56122cb5ef4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E5tLTKTLJvM3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import *\n",
        "from sklearn import metrics\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import LinearSVC,SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import KFold, ShuffleSplit\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "#plot\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H4vehgASId4m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "features = pd.read_csv('../gdrive/My Drive/super mario code/Test1_features.dat', sep=',', header=None)\n",
        "label = pd.read_csv('../gdrive/My Drive/super mario code/Test1_labels.dat', sep=',', header=None)\n",
        "# features.head()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tnI3PhlFIn3f",
        "colab_type": "code",
        "outputId": "8f6eebcd-1653-43d9-9e7e-173fa2d983e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "cell_type": "code",
      "source": [
        "#data exploration to check whether we need normalization and PCA\n",
        "# print(len(features))\n",
        "features.describe()#we need normalization for lr\n",
        "features.cov()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>20536.000000</td>\n",
              "      <td>20536.000000</td>\n",
              "      <td>20536.000000</td>\n",
              "      <td>20536.000000</td>\n",
              "      <td>20536.000000</td>\n",
              "      <td>20536.000000</td>\n",
              "      <td>20536.000000</td>\n",
              "      <td>20536.000000</td>\n",
              "      <td>20536.000000</td>\n",
              "      <td>20536.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>20536.000000</td>\n",
              "      <td>20536.000000</td>\n",
              "      <td>20536.000000</td>\n",
              "      <td>20536.000000</td>\n",
              "      <td>20536.000000</td>\n",
              "      <td>20536.000000</td>\n",
              "      <td>20536.000000</td>\n",
              "      <td>20536.000000</td>\n",
              "      <td>20536.000000</td>\n",
              "      <td>20536.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.280840</td>\n",
              "      <td>0.191621</td>\n",
              "      <td>0.200414</td>\n",
              "      <td>0.209932</td>\n",
              "      <td>0.219502</td>\n",
              "      <td>0.228368</td>\n",
              "      <td>0.235957</td>\n",
              "      <td>0.243107</td>\n",
              "      <td>0.249982</td>\n",
              "      <td>0.256800</td>\n",
              "      <td>...</td>\n",
              "      <td>0.004593</td>\n",
              "      <td>0.005001</td>\n",
              "      <td>0.006774</td>\n",
              "      <td>0.010448</td>\n",
              "      <td>0.004722</td>\n",
              "      <td>0.006377</td>\n",
              "      <td>0.006961</td>\n",
              "      <td>0.012285</td>\n",
              "      <td>0.022152</td>\n",
              "      <td>0.046366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.329204</td>\n",
              "      <td>0.204646</td>\n",
              "      <td>0.207465</td>\n",
              "      <td>0.210597</td>\n",
              "      <td>0.213606</td>\n",
              "      <td>0.215833</td>\n",
              "      <td>0.216641</td>\n",
              "      <td>0.217807</td>\n",
              "      <td>0.219981</td>\n",
              "      <td>0.222512</td>\n",
              "      <td>...</td>\n",
              "      <td>0.206832</td>\n",
              "      <td>0.203977</td>\n",
              "      <td>0.189287</td>\n",
              "      <td>0.222141</td>\n",
              "      <td>0.215072</td>\n",
              "      <td>0.221367</td>\n",
              "      <td>0.208717</td>\n",
              "      <td>0.236225</td>\n",
              "      <td>1.201108</td>\n",
              "      <td>2.009693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.002174</td>\n",
              "      <td>0.000525</td>\n",
              "      <td>0.000525</td>\n",
              "      <td>0.000540</td>\n",
              "      <td>0.000540</td>\n",
              "      <td>0.000532</td>\n",
              "      <td>0.000532</td>\n",
              "      <td>0.000541</td>\n",
              "      <td>0.000541</td>\n",
              "      <td>0.002174</td>\n",
              "      <td>...</td>\n",
              "      <td>-6.945700</td>\n",
              "      <td>-10.540000</td>\n",
              "      <td>-4.977000</td>\n",
              "      <td>-3.973000</td>\n",
              "      <td>-6.945700</td>\n",
              "      <td>-10.540000</td>\n",
              "      <td>-9.132000</td>\n",
              "      <td>-3.973000</td>\n",
              "      <td>-6.945700</td>\n",
              "      <td>-56.062000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.099018</td>\n",
              "      <td>0.040698</td>\n",
              "      <td>0.048296</td>\n",
              "      <td>0.055678</td>\n",
              "      <td>0.063409</td>\n",
              "      <td>0.071543</td>\n",
              "      <td>0.077776</td>\n",
              "      <td>0.082595</td>\n",
              "      <td>0.087183</td>\n",
              "      <td>0.091128</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.012340</td>\n",
              "      <td>-0.011992</td>\n",
              "      <td>-0.012900</td>\n",
              "      <td>-0.012500</td>\n",
              "      <td>-0.012700</td>\n",
              "      <td>-0.012200</td>\n",
              "      <td>-0.013100</td>\n",
              "      <td>-0.012700</td>\n",
              "      <td>-0.012830</td>\n",
              "      <td>-0.012253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.208715</td>\n",
              "      <td>0.123425</td>\n",
              "      <td>0.132115</td>\n",
              "      <td>0.141230</td>\n",
              "      <td>0.152040</td>\n",
              "      <td>0.162100</td>\n",
              "      <td>0.171015</td>\n",
              "      <td>0.179435</td>\n",
              "      <td>0.187105</td>\n",
              "      <td>0.194050</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002120</td>\n",
              "      <td>0.002100</td>\n",
              "      <td>0.002060</td>\n",
              "      <td>0.002120</td>\n",
              "      <td>0.002120</td>\n",
              "      <td>0.002100</td>\n",
              "      <td>0.002060</td>\n",
              "      <td>0.002120</td>\n",
              "      <td>0.002130</td>\n",
              "      <td>0.002110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.389085</td>\n",
              "      <td>0.269215</td>\n",
              "      <td>0.282680</td>\n",
              "      <td>0.293893</td>\n",
              "      <td>0.306603</td>\n",
              "      <td>0.318300</td>\n",
              "      <td>0.328265</td>\n",
              "      <td>0.339680</td>\n",
              "      <td>0.350170</td>\n",
              "      <td>0.360803</td>\n",
              "      <td>...</td>\n",
              "      <td>0.018400</td>\n",
              "      <td>0.018302</td>\n",
              "      <td>0.018200</td>\n",
              "      <td>0.018377</td>\n",
              "      <td>0.018625</td>\n",
              "      <td>0.018600</td>\n",
              "      <td>0.018600</td>\n",
              "      <td>0.018700</td>\n",
              "      <td>0.019200</td>\n",
              "      <td>0.019100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>10.526000</td>\n",
              "      <td>1.594900</td>\n",
              "      <td>1.594900</td>\n",
              "      <td>1.594900</td>\n",
              "      <td>1.594900</td>\n",
              "      <td>1.594900</td>\n",
              "      <td>1.594900</td>\n",
              "      <td>1.594900</td>\n",
              "      <td>1.756800</td>\n",
              "      <td>1.756800</td>\n",
              "      <td>...</td>\n",
              "      <td>6.911100</td>\n",
              "      <td>6.523700</td>\n",
              "      <td>4.685600</td>\n",
              "      <td>13.894000</td>\n",
              "      <td>6.911100</td>\n",
              "      <td>6.757000</td>\n",
              "      <td>4.685600</td>\n",
              "      <td>13.894000</td>\n",
              "      <td>101.300000</td>\n",
              "      <td>99.892000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 61 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 0             1             2             3             4   \\\n",
              "count  20536.000000  20536.000000  20536.000000  20536.000000  20536.000000   \n",
              "mean       0.280840      0.191621      0.200414      0.209932      0.219502   \n",
              "std        0.329204      0.204646      0.207465      0.210597      0.213606   \n",
              "min        0.002174      0.000525      0.000525      0.000540      0.000540   \n",
              "25%        0.099018      0.040698      0.048296      0.055678      0.063409   \n",
              "50%        0.208715      0.123425      0.132115      0.141230      0.152040   \n",
              "75%        0.389085      0.269215      0.282680      0.293893      0.306603   \n",
              "max       10.526000      1.594900      1.594900      1.594900      1.594900   \n",
              "\n",
              "                 5             6             7             8             9   \\\n",
              "count  20536.000000  20536.000000  20536.000000  20536.000000  20536.000000   \n",
              "mean       0.228368      0.235957      0.243107      0.249982      0.256800   \n",
              "std        0.215833      0.216641      0.217807      0.219981      0.222512   \n",
              "min        0.000532      0.000532      0.000541      0.000541      0.002174   \n",
              "25%        0.071543      0.077776      0.082595      0.087183      0.091128   \n",
              "50%        0.162100      0.171015      0.179435      0.187105      0.194050   \n",
              "75%        0.318300      0.328265      0.339680      0.350170      0.360803   \n",
              "max        1.594900      1.594900      1.594900      1.756800      1.756800   \n",
              "\n",
              "           ...                 51            52            53            54  \\\n",
              "count      ...       20536.000000  20536.000000  20536.000000  20536.000000   \n",
              "mean       ...           0.004593      0.005001      0.006774      0.010448   \n",
              "std        ...           0.206832      0.203977      0.189287      0.222141   \n",
              "min        ...          -6.945700    -10.540000     -4.977000     -3.973000   \n",
              "25%        ...          -0.012340     -0.011992     -0.012900     -0.012500   \n",
              "50%        ...           0.002120      0.002100      0.002060      0.002120   \n",
              "75%        ...           0.018400      0.018302      0.018200      0.018377   \n",
              "max        ...           6.911100      6.523700      4.685600     13.894000   \n",
              "\n",
              "                 55            56            57            58            59  \\\n",
              "count  20536.000000  20536.000000  20536.000000  20536.000000  20536.000000   \n",
              "mean       0.004722      0.006377      0.006961      0.012285      0.022152   \n",
              "std        0.215072      0.221367      0.208717      0.236225      1.201108   \n",
              "min       -6.945700    -10.540000     -9.132000     -3.973000     -6.945700   \n",
              "25%       -0.012700     -0.012200     -0.013100     -0.012700     -0.012830   \n",
              "50%        0.002120      0.002100      0.002060      0.002120      0.002130   \n",
              "75%        0.018625      0.018600      0.018600      0.018700      0.019200   \n",
              "max        6.911100      6.757000      4.685600     13.894000    101.300000   \n",
              "\n",
              "                 60  \n",
              "count  20536.000000  \n",
              "mean       0.046366  \n",
              "std        2.009693  \n",
              "min      -56.062000  \n",
              "25%       -0.012253  \n",
              "50%        0.002110  \n",
              "75%        0.019100  \n",
              "max       99.892000  \n",
              "\n",
              "[8 rows x 61 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "hVaHffEE-ajc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "haX5kafn1jDi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#input: X_train, Y_train and X_test\n",
        "#output: Y_pred\n",
        "def logistic_regression_pred(X_train, Y_train, X_test):\n",
        "\t#TODO: train a logistic regression classifier using X_train and Y_train. Use this to predict labels of X_test\n",
        "\t#use default params for the classifier\t\n",
        "\tclf = LogisticRegression()\n",
        "\tclf.fit(X_train, Y_train)\n",
        "\treturn clf.predict(X_test)\n",
        "# 0.88\n",
        "\n",
        "#input: X_train, Y_train and X_test\n",
        "#output: Y_pred\n",
        "def svm_pred(X_train, Y_train, X_test):\n",
        "\t#TODO:train a SVM classifier using X_train and Y_train. Use this to predict labels of X_test\n",
        "\t#use default params for the classifier\n",
        "\tclf = LinearSVC()\n",
        "\tclf.fit(X_train, Y_train)\n",
        "\treturn clf.predict(X_test)\n",
        "# linear nonconverge\n",
        "\n",
        "#RBF\n",
        "def RBF_pred(X_train, Y_train, X_test):\n",
        "    clf=SVC(gamma=2, C=1)\n",
        "    clf.fit(X_train, Y_train)\n",
        "    return clf.predict(X_test)\n",
        "#   0.9479777681911463\n",
        "  \n",
        "def GP_pred(X_train, Y_train, X_test):\n",
        "    clf=GaussianProcessClassifier(1.0 * RBF(1.0))\n",
        "    clf.fit(X_train, Y_train)\n",
        "    return clf.predict(X_test)\n",
        "  \n",
        "#  out of memory\n",
        "    \n",
        "\n",
        "#input: X_train, Y_train and X_test\n",
        "#output: Y_pred\n",
        "def decisionTree_pred(X_train, Y_train, X_test):\n",
        "\t#TODO:train a logistic regression classifier using X_train and Y_train. Use this to predict labels of X_test\n",
        "\t#IMPORTANT: use max_depth as 5. Else your test cases might fail.\n",
        "\tclf = DecisionTreeClassifier(max_depth=5)\n",
        "\tclf.fit(X_train, Y_train)\n",
        "\treturn clf.predict(X_test)\n",
        "# 0.9550866827440643\n",
        "\n",
        "def RandomForest_pred(X_train, Y_train, X_test):\n",
        "  clf3 = RandomForestClassifier(n_estimators=100,random_state = RANDOM_STATE)\n",
        "  clf3.fit(X_train, Y_train)\n",
        "  return clf3.predict(X_test)\n",
        "#0.9786690591704268\n",
        " \n",
        "def AdaBoost_pred(X_train, Y_train, X_test):\n",
        "  clf1=AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2), n_estimators=100, learning_rate=1.0,random_state = RANDOM_STATE)\n",
        "  clf1.fit(X_train,Y_train)\n",
        "  return clf1.predict(X_test)\n",
        "# 0.980443214964642\n",
        "\n",
        "\n",
        "def GradientBoost_pred(X_train, Y_train, X_test):\n",
        "  clf2 = GradientBoostingClassifier()\n",
        "  clf2.fit(X_train, Y_train)\n",
        "  return clf2.predict(X_test)\n",
        "# 0.9796705098567797\n",
        "\n",
        "\n",
        "def XGBoost_pred(X_train, Y_train, X_test):\n",
        "  param = {'max_depth': 2, 'eta': 1, 'silent': 1, 'objective': 'binary:logistic',\n",
        "          'nthread':2, 'eval_metric':'auc'}\n",
        "  xgb_model = xgb.XGBClassifier().fit(X_train, Y_train)\n",
        "  return xgb_model.predict(X_test)\n",
        "#0.9654063047245753\n",
        "\n",
        "    \n",
        "\n",
        "def MLP_pred(X_train, Y_train, X_test):\n",
        "\n",
        "  clf=MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto',\n",
        "              beta_1=0.9, beta_2=0.999, early_stopping=False,\n",
        "              epsilon=1e-08, hidden_layer_sizes=(25, 15),\n",
        "              learning_rate='constant', learning_rate_init=0.01,\n",
        "              max_iter=1000, momentum=0.9, n_iter_no_change=10,\n",
        "              nesterovs_momentum=True, power_t=0.5, random_state=1,\n",
        "              shuffle=True, solver='lbfgs', tol=0.0001,\n",
        "              validation_fraction=0.1, verbose=False, warm_start=False)\n",
        "  clf.fit(X_train, Y_train)\n",
        "  return clf.predict(X_test)\n",
        "# 0.9704230666219459\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qmMqASYG9ijw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "RANDOM_STATE=123\n",
        "features=np.array(features)\n",
        "label=np.array(label)\n",
        "\n",
        "#after pca we get a relatively poorer result 0.965 on adaboost, but faster.\n",
        "# Here we still use with the PCA in case of overfitting.\n",
        "pca = PCA(n_components = 0.85, svd_solver = 'full')\n",
        "pipe = Pipeline(steps=[('scaler', StandardScaler()),('pca', pca) ])\n",
        "features_tran=pipe.fit_transform(features)\n",
        "# 0.9688964744883982\n",
        "\n",
        "# scaler=StandardScaler()\n",
        "# features_tran=scaler.fit_transform(features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wARt_rHABQXr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nnUntjbuIrCv",
        "colab_type": "code",
        "outputId": "46042ba4-3a56-4d34-ac45-68fabc29f588",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "cell_type": "code",
      "source": [
        "#input: training data and corresponding labels\n",
        "#output: auc\n",
        "\n",
        "def get_auc_kfold(Best_Model,X,Y,k=5):\n",
        "#TODO:First get the train indices and test indices for each iteration\n",
        "#Then train the classifier accordingly\n",
        "#mean auc of all the folds\n",
        "  kf=KFold(n_splits=k, random_state=RANDOM_STATE, shuffle=True)\n",
        "  kf.get_n_splits(X)\n",
        "  T_auc=0.0\n",
        "  \n",
        "  for train_index, test_index in kf.split(X):\n",
        "    Y_pred=Best_Model(X[train_index], Y[train_index], X[test_index])\n",
        "    auc=metrics.roc_auc_score(Y[test_index], Y_pred)\n",
        "    T_auc+=auc\n",
        "  return T_auc/k\n",
        "\n",
        "\n",
        "print(get_auc_kfold(AdaBoost_pred,features_tran,label))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.9688964744883982\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BRuPaHZLIrCI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# \tGrid Search on Best Model\n",
        "# adaboost gives the best result here, but xgboost is more practice w.r.t. speed.\n",
        "import multiprocessing\n",
        "import warnings\n",
        "\n",
        "n_jobs=multiprocessing.cpu_count()\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "clf = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2),\n",
        "                         n_estimators=100, learning_rate=1.0,\n",
        "                         random_state = RANDOM_STATE)\n",
        " \n",
        "param_dic = {\"n_estimators\": np.arange(50, 200),\n",
        "             \"learning_rate\": np.arange(0.01, 1.5, 0.02)}\n",
        " \n",
        "grid_clf = GridSearchCV(clf, param_grid=param_dic, scoring='roc_auc', cv=5, n_jobs=n_jobs)\n",
        "grid_clf.fit(features_tran, label)\n",
        "Y_pred=grid_clf.predict(features_tran)\n",
        "auc=metrics.roc_auc_score(label, Y_pred)\n",
        "print(auc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CVET6nMXpdwP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y_pred=grid_clf.predict(features_tran)\n",
        "auc=metrics.roc_auc_score(label, Y_pred)\n",
        "print(auc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x1rX7SeJG0ux",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "best_params=grid_clf.best_params_\n",
        "cv_results=pd.DataFrame(grid_clf.cv_results_)\n",
        "cv_results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VI_2DtdRqPlk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "param1=param_dic['n_estimators']\n",
        "param2=param_dic['learning_rate']\n",
        "scores = grid_clf.cv_results_['mean_test_score'].reshape(len(param2),len(param1))\n",
        "scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "79qp96N5sliU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X, Y = np.meshgrid(param1, param2)\n",
        "print (X)\n",
        "print (Y)\n",
        "print (X.shape)\n",
        "print (Y.shape)\n",
        "print (scores.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fBD038r65pV7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8ktuURrQReSB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "======================\n",
        "3D surface (color map)\n",
        "======================\n",
        "\n",
        "Demonstrates plotting a 3D surface colored with the coolwarm color map.\n",
        "The surface is made opaque by using antialiased=False.\n",
        "\n",
        "Also demonstrates using the LinearLocator and custom formatting for the\n",
        "z axis tick labels.\n",
        "'''\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.gca(projection='3d')\n",
        "\n",
        "# Make data.\n",
        "param1=param_dic['n_estimators']\n",
        "param2=param_dic['learning_rate']\n",
        "\n",
        "X, Y = np.meshgrid(param1, param2)\n",
        "Z = grid_clf.cv_results_['mean_test_score'].reshape(len(param2),len(param1))\n",
        "\n",
        "\n",
        "# Plot the surface.\n",
        "surf = ax.plot_surface(X, Y, Z, cmap=cm.coolwarm,\n",
        "                       linewidth=0, antialiased=False)\n",
        "\n",
        "# Customize the z axis.\n",
        "# ax.set_zlim(0.97, 0.99)\n",
        "ax.zaxis.set_major_locator(LinearLocator(10))\n",
        "ax.zaxis.set_major_formatter(FormatStrFormatter('%.03f'))\n",
        "\n",
        "# Add a color bar which maps values to colors.\n",
        "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_-xgnF-Lb6QB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}